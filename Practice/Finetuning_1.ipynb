{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Supervised Fine-Tuning (in 5 steps)\n",
        "\n",
        "1. Choose fine-tuning task\n",
        "2. Prepare training dataset\n",
        "3. Choose a Base Model\n",
        "4. Fine-tune model via Supervised Learning\n",
        "5. Evaluate Model Performance"
      ],
      "metadata": {
        "id": "qfRzQuBN8XV0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "-Y2d7JCDcIEk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "853b4a75-ebe7-47c2-8174-5563f076d731"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.10.1)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.12/dist-packages (0.17.1)\n",
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.12/dist-packages (0.47.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.55.4)\n",
            "Requirement already satisfied: trl in /usr/local/lib/python3.12/dist-packages (0.22.1)\n",
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.5-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.12/dist-packages (from accelerate) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (25.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from accelerate) (6.0.2)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (2.8.0+cu126)\n",
            "Requirement already satisfied: huggingface_hub>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (0.34.4)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from accelerate) (0.6.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from peft) (4.67.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.19.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.21.4)\n",
            "Requirement already satisfied: datasets>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from trl) (4.0.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from evaluate) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.3.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=3.0.0->trl) (18.1.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (3.12.15)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (1.1.8)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.8.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.20.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
            "Downloading evaluate-0.4.5-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: evaluate\n",
            "Successfully installed evaluate-0.4.5\n"
          ]
        }
      ],
      "source": [
        "!pip install accelerate peft bitsandbytes transformers trl evaluate"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset,DatasetDict, Dataset\n",
        "\n",
        "from transformers import (\n",
        "    AutoModelForSequenceClassification,\n",
        "    AutoTokenizer,\n",
        "    AutoConfig,\n",
        "    DataCollatorWithPadding,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        ")\n",
        "\n",
        "from peft import LoraConfig, PeftModel, PeftConfig, get_peft_model\n",
        "import evaluate\n",
        "import torch\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "MeEbm-T111Sg"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_checkpoint =  \"distilbert-base-uncased\" # base model we're gonna use\n",
        "\n",
        "# define label maps for sentiment analysis\n",
        "id2label = {0: \"NEGATIVE\", 1: \"POSITIVE\"}\n",
        "label2id = {\"NEGATIVE\": 0, \"POSITIVE\": 1}\n",
        "\n",
        "# generate classification model from model_checkpoint\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    model_checkpoint, num_labels=2, id2label=id2label, label2id=label2id\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136,
          "referenced_widgets": [
            "9c938754b0734a479b4a89e97e137fff",
            "51a4487eb2674b41bcfc6537ea2b3d1c",
            "0246cfced9a64cbb94ca99f53d6db23f",
            "c591aa37f9d94479a6e89f5b8e179755",
            "64e17b506f594cf1ade2361dc2787735",
            "6cc463307cb843fc88e0e995f7a027c1",
            "de8cc36f264347d097f238bff409a643",
            "25b738ab9a70460b8c1d35a2a50c5996",
            "335b3fca3ecc497d80847fc6a4ac39ca",
            "eb21fea94a8547648441618bda355224",
            "0fdc026800a0457d828a45d097096187",
            "16fe5122c3274ad191d3fe0e67adbdee",
            "8e65df661f6e4b3f8f3dde6fc83990bb",
            "5a4d3ff033f8466a97e96d8de5d63736",
            "eea13bbbfc8c4b4dace2f47e00f5e8ef",
            "4e46efd4b3b54dc89859685548290b95",
            "1732230e831a4bcaaa9efd8729c5a94a",
            "b85fef47bcb2446ca9767b67ca7db804",
            "17d18b5e75c742589342ce70e6d64186",
            "74e2b1ac49084b21bede821393e2b7dd",
            "cbaef1e8506c49af8da14e6ce1114024",
            "d6fad363a186412a9f10bf8c24609eca"
          ]
        },
        "id": "52qC7MdV2i1x",
        "outputId": "f1a562af-c447-4528-a86f-a4e4fa7e3033"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9c938754b0734a479b4a89e97e137fff"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "16fe5122c3274ad191d3fe0e67adbdee"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load dataset\n",
        "\n",
        "dataset = load_dataset(\"shawhin/imdb-truncated\")\n",
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351,
          "referenced_widgets": [
            "c2ea484bffb24c37a9dad2786a6c4f94",
            "7182becbf7d24660b86de4d1f618016b",
            "40f6a05378124ce59ea05ca672f60474",
            "7e00dda24fae4c2caa610b526c27e264",
            "4ad0992560ef4fb6bc6ed8e856d4f744",
            "296470d3c9324b299eb5df69ce1a227b",
            "5fe6ac54155f48f8b2313a5c49a554db",
            "785fe6dd33e04a54a654eb8391ac2ce4",
            "6550c0b28eb849248df2464b64372b8e",
            "1595f6526aa3483297f8e4fbffbc38b6",
            "e87746172cc04ac0a977366ca9566543",
            "3a0f874e5aca46639682a7cedf9b0550",
            "b43e252c2d1a464d8db44551d4d36a67",
            "8e9b4a53e0f34d58b024984baf1065f7",
            "af6f6ae78a3b4bf984082882936ae9a2",
            "fce7fa3cc26142df84ae1f1586c6dbcb",
            "59917e38bc9d4581bea16e67f5eb99bd",
            "621bc910d8a147fc84da3f21ebf5d1b2",
            "835fa3e7c46344068e6a74a3194895c6",
            "871306a3ff6e4c5fb0a937944aeeef0d",
            "b83718c87b5f449fb2fbb1a489712542",
            "8f37fc7480c14340b2d3f83307fe436a",
            "33671ee49e454624ab4c1d2c95f56bd2",
            "8c5ec6d2bd9948208a971e933c890e61",
            "7cb60f1507b74ff5aad6ad962d98ddad",
            "7e491ad8d30a4d9db78f5f7e10899f21",
            "5f5e86314a2749eaaaee8c5958858cba",
            "8d444a4e315847a387f34b341b44eb11",
            "b827d9102e5048e4b7c9595eb31f3762",
            "5c2c6b94b23e4964bdb4946c8abdf1ff",
            "a931510debed4e0b867fc4b7dba7a239",
            "47630776c4d54fb2964f9bff8a4988d6",
            "4d2c92341fd2499f95addfd860bd70d3",
            "4d02065708b649798b14f37736481d5b",
            "48da1cf083d44455a308d6fdd30bbc22",
            "24ebc83883ff4305bc8d5d8643cfa15f",
            "729e3f7d0b5344959aea9fb03665f79b",
            "630bb637825740cb88719bafae878789",
            "754f1ff224e949a88cdfc3cda90dedd7",
            "3ffd75a231154f2aba7a5974bd23d176",
            "6b42c6413e2a430fbd460a3fe729ae5f",
            "507f03c83fa2492cb6e46e1386783782",
            "e50dab24eb9c4dc382968c272734f56c",
            "0860aa68d28f49be95cd06cc50944bca",
            "a6ac1428e13e4239aa2e3b8c3e959999",
            "a6cc6a4290aa4afdb7806fdc01163d15",
            "9ec61802f6f64590af403ba5f3943aa9",
            "5eba6dd98d4940798cbe2bd5aa4cf6da",
            "2b670932f8974ff2b2247a880ded34a2",
            "8996f89b5b494243813703ee7e30b2fb",
            "ab1d7bc9b90343ce8948f054aee2d7b2",
            "7ef70adb20c6478796fe5f1522dec722",
            "1fc83f498526492aa41036294fdea6ae",
            "10e2b4b5d831485d939abf093887de8a",
            "ed8c340d58ac479c96d12c273789cc98"
          ]
        },
        "id": "ux-UE-JR5HT_",
        "outputId": "294966c9-ff43-47d7-db3d-bc3defa1a536"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/592 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c2ea484bffb24c37a9dad2786a6c4f94"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "data/train-00000-of-00001-5a744bf76a1d84(…):   0%|          | 0.00/836k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3a0f874e5aca46639682a7cedf9b0550"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "data/validation-00000-of-00001-a3a52fabb(…):   0%|          | 0.00/853k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "33671ee49e454624ab4c1d2c95f56bd2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/1000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4d02065708b649798b14f37736481d5b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating validation split:   0%|          | 0/1000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a6ac1428e13e4239aa2e3b8c3e959999"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['label', 'text'],\n",
              "        num_rows: 1000\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['label', 'text'],\n",
              "        num_rows: 1000\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# preprocess data\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, add_prefix_spce = True)\n",
        "\n",
        "# create tokenize function\n",
        "\n",
        "def tokenize_function(examples):\n",
        "  # extract text\n",
        "  text = examples['text']\n",
        "\n",
        "  # tokenize and truncate text\n",
        "  tokenizer.truncation_side = \"left\"\n",
        "  tokenized_inputs = tokenizer(\n",
        "      text,\n",
        "      return_tensors = \"np\",\n",
        "      truncation = True,\n",
        "      max_length = 512,\n",
        "  )\n",
        "\n",
        "  return tokenized_inputs\n",
        "\n",
        "# add pad token if none exists\n",
        "if tokenizer.pad_token is None:\n",
        "  tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
        "  model.resize_token_embeddings(len(tokenizer))\n",
        "\n",
        "# tokenize training and validation datasets\n",
        "tokenized_datasets = dataset.map(tokenize_function, batched = True)\n",
        "tokenized_datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351,
          "referenced_widgets": [
            "453d2707ad5a4c2c90253c15ace90168",
            "0dadc280a5614d35bbd6acee328786cd",
            "6c7df1147a1d449ba4f2cabd773b651a",
            "9877850081984420b4080e22d7b12783",
            "55f245badfd941728c868f32e437bba4",
            "1b5e8ecba54043108818a5ab44fbf81f",
            "9fcc8686dad448429815c1872a5fb1e6",
            "1d6ae29297e24f66bb9f694b2b36b737",
            "c2212adf95cf4deaabeb76407986b665",
            "fa3724d762004b41bb1fe662f1337a71",
            "a67890085ee44d1d9ed6441e65614cf1",
            "6980c362864a49e6a191fe0ffed179ae",
            "b05e0b5074be433881cc987d523d0b42",
            "97852fc0fe8947ba904a53802b91ee0f",
            "022854c6d0024a40bfbf4632984d21d6",
            "95d815cb8a1240f3b2e6d7bac3580481",
            "83c6cf2fc7c5481ebe9cd98fe5f0dd03",
            "37a2e8ac4d7b4f21b7c8138571aa8ca1",
            "3626144f804b4552af97d1c2b0e39bdf",
            "aef924018b894c74a53727e6129f3423",
            "740da44b9037435aa03488190461b488",
            "f24bab7870bc43fd845e4d166354d8fd",
            "f3aa6385a40d418fab21c3d1bca1a2c6",
            "f778675539d44163b0adc0b3fdc94b16",
            "80a8a93e2a204d09af1dc2703bde7e82",
            "08026cfdc0064f6b9f0ee3f01b2a92cc",
            "802c7d1995974de781637452b722d56a",
            "a095d1fb8dc04ce78759d1d86f75e7f4",
            "bd6f979aaa9340b8bb701b96490bf7e7",
            "2bf0b9a762ad4b3592708e0d5f2d5d4f",
            "4fd5b197640a4a9da0daf8f5e6ca0a74",
            "e8bea3dc46cc46038364b8c267c57699",
            "e68bbfa2aec34e94a755c18bb3881af5",
            "da12477561e14d9695f22a4065040b06",
            "722e33e4c82047ccb1b5bb1ca9896a1e",
            "324d19128b864c968913a7153969b969",
            "83a1e7bb2e5d4ddd882ef00344d68308",
            "46d43b9c9e4b4b66ae5806534fb70c8b",
            "63b25816289248d6aa7e05c191f32639",
            "82b40a4f441a4d88a7bb5675d161b4ad",
            "ea8a8c0157af4359a852a82855c9d866",
            "5c152dfb20d54cb29c3b90fce7e4ff95",
            "a873021abd1a4cc8ac5e954ebfccde5d",
            "3774ec8129964b27a838338e004af5d6",
            "d9231adec668486e81b9cb1376a2cc75",
            "792212a2c95d4057875747ebcb728bb9",
            "b85d605f7e474ab58bf74c49e8e50b6e",
            "56a1d09ba19746e7b1508336022819d1",
            "ae7430d201bb488d9e276c47936860e8",
            "9940a761ae314775878e5863486a6873",
            "34154ecd5fe3426bac27695eee46b524",
            "4fb61e1855884157bed4a9a6df7d9754",
            "2d77e5b1c6824e04961098aeb1d26fec",
            "dc1c61d72c244fae9f26a99cc53248f8",
            "8d0fab6e97c7444ca09171772500a579"
          ]
        },
        "id": "VW6S88yd5KJ5",
        "outputId": "99b0501b-2cf4-40fd-f618-9af811ef9944"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "453d2707ad5a4c2c90253c15ace90168"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6980c362864a49e6a191fe0ffed179ae"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f3aa6385a40d418fab21c3d1bca1a2c6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "da12477561e14d9695f22a4065040b06"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d9231adec668486e81b9cb1376a2cc75"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['label', 'text', 'input_ids', 'attention_mask'],\n",
              "        num_rows: 1000\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['label', 'text', 'input_ids', 'attention_mask'],\n",
              "        num_rows: 1000\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create data collator\n",
        "data_collator = DataCollatorWithPadding(tokenizer = tokenizer)"
      ],
      "metadata": {
        "id": "JMW1gUIa5L6w"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# EVALUATION METRICS\n",
        "\n",
        "# import accuracy eval func\n",
        "accuracy = evaluate.load(\"accuracy\")\n",
        "\n",
        "# define an eval func to pass into trainer later\n",
        "def compute_metrics(p):\n",
        "  predictions, labels = p\n",
        "  predictions = np.argmax(predictions, axis = 1)\n",
        "\n",
        "  return {\"accuracy\": accuracy.compute(predictions = predictions, references = labels)}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "68970e089353447f84298d5f6be31eb7",
            "25c0940fb92247898e00e0285de6ef97",
            "89c8542009504f5c80a54d5697077798",
            "35f0ae3eaa474240ba426db528fc8127",
            "aa44f18c112944dbb5280fb07781078d",
            "1987492d493649a5bc96896031fea10c",
            "ea922f8a1eb049a8a9ce266e0cd95de3",
            "b9c0d22d10a641aca6c1ce31cd42318c",
            "9e07b3fd80d9451ba4a6631fc5268b41",
            "ac73727c969c42c1962c4cd440c86816",
            "2c5b7d4ef20642d39d1b6dad64e2b474"
          ]
        },
        "id": "DYMGGTtm_t42",
        "outputId": "77d1a301-3fe3-42c2-a970-835b5ae37940"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "68970e089353447f84298d5f6be31eb7"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# untrained model performance\n",
        "\n",
        "text_list = [\"It was good.\", \"Not a fan don't recommend.\",\n",
        "             \"Better than the first one.\", \"This is not worth watching even once\",\n",
        "             \"This one is a pass.\"]\n",
        "\n",
        "print(\"Untrained model predictions:\")\n",
        "print(\"----------------------------\")\n",
        "for text in text_list:\n",
        "  # tokenize text\n",
        "  inputs = tokenizer.encode(text, return_tensors = \"pt\")\n",
        "  # compute logits\n",
        "  logits = model(inputs).logits\n",
        "  # convert logits to label\n",
        "  predictions = torch.argmax(logits)\n",
        "\n",
        "  print(text + \" - \" + id2label[predictions.tolist()])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X1bmI4CTAe9d",
        "outputId": "df2284d6-2416-4508-9503-cc97e8dd06af"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Untrained model predictions:\n",
            "----------------------------\n",
            "It was good. - POSITIVE\n",
            "Not a fan don't recommend. - POSITIVE\n",
            "Better than the first one. - POSITIVE\n",
            "This is not worth watching even once - POSITIVE\n",
            "This one is a pass. - POSITIVE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fine-tuning with LoRA\n",
        "\n",
        "peft_config = LoraConfig(task_type = \"SEQ_CLS\",  # seq classification\n",
        "                         r = 4, # rank\n",
        "                         lora_alpha = 32, # like learing rate\n",
        "                         lora_dropout = 0.01, # probability of dropout\n",
        "                         target_modules = ['q_lin'])  # we apply lora to query layer"
      ],
      "metadata": {
        "id": "8Lusonp7Bncw"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = get_peft_model(model, peft_config)\n",
        "model.print_trainable_parameters()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wf36M-PJCkz1",
        "outputId": "c8a265f9-3f1d-4b08-c6b8-e7aae934d2ea"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable params: 628,994 || all params: 67,584,004 || trainable%: 0.9307\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# hyperparamters\n",
        "lr = 1e-3 # size of optim step\n",
        "batch_size = 4\n",
        "num_epochs = 10\n",
        "\n",
        "# def training arg\n",
        "training_args = TrainingArguments(\n",
        "    output_dir = model_checkpoint + \"-lora-text-classification\",  # giving a name to our finetuned model\n",
        "    learning_rate = lr,\n",
        "    per_device_train_batch_size = batch_size,\n",
        "    per_device_eval_batch_size = batch_size,\n",
        "    num_train_epochs = num_epochs,\n",
        "    weight_decay = 0.01,\n",
        "    )"
      ],
      "metadata": {
        "id": "rNKtwMqCCoP0"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create trainer object\n",
        "trainer = Trainer(\n",
        "    model = model,\n",
        "    args = training_args,\n",
        "    train_dataset = tokenized_datasets[\"train\"],\n",
        "    eval_dataset = tokenized_datasets[\"validation\"],\n",
        "    tokenizer = tokenizer,\n",
        "    data_collator = data_collator,\n",
        "    compute_metrics = compute_metrics,\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        },
        "id": "nJwMT2N7DWVe",
        "outputId": "d05bc271-5179-4641-8a10-84166d2b95d8"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2224708600.py:2: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize?ref=models\n",
            "wandb: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mshivangshandilya83\u001b[0m (\u001b[33mshivangshandilya83-independent\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.21.1"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250830_034212-p710ted1</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/shivangshandilya83-independent/huggingface/runs/p710ted1' target=\"_blank\">likely-river-2</a></strong> to <a href='https://wandb.ai/shivangshandilya83-independent/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/shivangshandilya83-independent/huggingface' target=\"_blank\">https://wandb.ai/shivangshandilya83-independent/huggingface</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/shivangshandilya83-independent/huggingface/runs/p710ted1' target=\"_blank\">https://wandb.ai/shivangshandilya83-independent/huggingface/runs/p710ted1</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2500' max='2500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2500/2500 05:01, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.427900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.180700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.060600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.017000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.007900</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=2500, training_loss=0.13882831783294677, metrics={'train_runtime': 331.5995, 'train_samples_per_second': 30.157, 'train_steps_per_second': 7.539, 'total_flos': 1112883852759936.0, 'train_loss': 0.13882831783294677, 'epoch': 10.0})"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# using the same sample as before ion trained model this time\n",
        "model.to('cpu')\n",
        "\n",
        "print(\"Trained model predictions:\")\n",
        "print(\"----------------------------\")\n",
        "for text in text_list:\n",
        "  # tokenize text\n",
        "  inputs = tokenizer.encode(text, return_tensors = \"pt\").to('cpu')\n",
        "  # compute logits\n",
        "  logits = model(inputs).logits\n",
        "  # convert logits to label\n",
        "  predictions = torch.max(logits, 1).indices\n",
        "\n",
        "  print(text + \" - \" + id2label[predictions.tolist()[0]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lI2TrKGbELSV",
        "outputId": "d197abd6-1ea5-418f-feaa-bfea5db39278"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trained model predictions:\n",
            "----------------------------\n",
            "It was good. - POSITIVE\n",
            "Not a fan don't recommend. - NEGATIVE\n",
            "Better than the first one. - POSITIVE\n",
            "This is not worth watching even once - POSITIVE\n",
            "This one is a pass. - NEGATIVE\n"
          ]
        }
      ]
    }
  ]
}
